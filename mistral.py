import os
import pandas as pd
from transformers import AutoTokenizer, AutoModelForCausalLM
from sklearn.metrics import accuracy_score, f1_score
import torch
import re

# Load and clean both train and dev data
train_path = "/users/PAS2836/krishnakb/ondemand/krishna_proj/Task1/train_data_SMM4H_2025_Task_1.csv"
dev_path = "/users/PAS2836/krishnakb/ondemand/krishna_proj/Task1/dev_data_SMM4H_2025_Task_1.csv"
train_df = pd.read_csv(train_path)
dev_df = pd.read_csv(dev_path)

def clean_text(text):
    text = re.sub(r'@User|<user>', '', text)
    text = re.sub(r'http\S+|www\.\S+', '[URL]', text)
    emoji_pattern = re.compile("[" u"\U0001F600-\U0001F64F" u"\U0001F300-\U0001F5FF" u"\U0001F680-\U0001F6FF" u"\U0001F1E0-\U0001F1FF" "]+", flags=re.UNICODE)
    text = emoji_pattern.sub(r'', text)
    text = re.sub(r'\s+', ' ', text).strip()
    return text

for df_ in [train_df, dev_df]:
    df_['text'] = df_['text'].astype(str).apply(clean_text)

# Combine both datasets
full_df = pd.concat([train_df, dev_df]).reset_index(drop=True)

# Downsample majority class (Non-ADE)
pos_df = full_df[full_df['label'] == 1]
neg_df = full_df[full_df['label'] == 0].sample(len(pos_df) * 10, random_state=42)
df = pd.concat([pos_df, neg_df]).sample(frac=1, random_state=42).reset_index(drop=True)

# Define language-specific few-shot prompts
prompt_dict = {
    "en": """
Classify the following tweet as either 'ADE' or 'Non-ADE'. Respond with only one of the two labels: ADE or Non-ADE.

Tweet: "I started taking Ibuprofen and now have severe headaches."
Label: ADE

Tweet: "Love this sunny weather! No meds today."
Label: Non-ADE

Tweet: "After taking paracetamol, I developed a rash on my arms."
Label: ADE

Tweet: "I‚Äôve been off meds for a week and feeling fine."
Label: Non-ADE

Tweet: "Took Metformin this morning and had terrible stomach cramps."
Label: ADE

Tweet: "Went for a walk and enjoyed the fresh air."
Label: Non-ADE

Tweet: """ ,

    "ru": """
–û–ø—Ä–µ–¥–µ–ª–∏—Ç–µ, —Å–æ–¥–µ—Ä–∂–∏—Ç –ª–∏ —Ç–≤–∏—Ç –ø–æ–±–æ—á–Ω–æ–µ –¥–µ–π—Å—Ç–≤–∏–µ (ADE) –∏–ª–∏ –Ω–µ—Ç. –û—Ç–≤–µ—Ç—å—Ç–µ —Ç–æ–ª—å–∫–æ 'ADE' –∏–ª–∏ 'Non-ADE'.

Tweet: "–Ø –ø—Ä–∏–Ω—è–ª –∏–±—É–ø—Ä–æ—Ñ–µ–Ω –∏ –ø–æ—á—É–≤—Å—Ç–≤–æ–≤–∞–ª —Å–∏–ª—å–Ω—É—é –≥–æ–ª–æ–≤–Ω—É—é –±–æ–ª—å."
Label: ADE

Tweet: "–ü—Ä–æ—Å—Ç–æ –ø–æ—à—ë–ª –Ω–∞ –ø—Ä–æ–≥—É–ª–∫—É, –Ω–∏–∫–∞–∫–∏—Ö –ª–µ–∫–∞—Ä—Å—Ç–≤."
Label: Non-ADE

Tweet: "–ü–æ—Å–ª–µ –ø–∞—Ä–∞—Ü–µ—Ç–∞–º–æ–ª–∞ –ø–æ—è–≤–∏–ª–∞—Å—å —Å—ã–ø—å –Ω–∞ –∫–æ–∂–µ."
Label: ADE

Tweet: "–ü—å—é –≤–∏—Ç–∞–º–∏–Ω—ã, —á—É–≤—Å—Ç–≤—É—é —Å–µ–±—è –æ—Ç–ª–∏—á–Ω–æ."
Label: Non-ADE

Tweet: "–ü—Ä–∏–Ω—è–ª –∞—Å–ø–∏—Ä–∏–Ω, –Ω–∞—á–∞–ª–∞—Å—å —Ç–æ—à–Ω–æ—Ç–∞ –∏ –≥–æ–ª–æ–≤–æ–∫—Ä—É–∂–µ–Ω–∏–µ."
Label: ADE

Tweet: "–°–º–æ—Ç—Ä—é —Ñ–∏–ª—å–º –∏ –æ—Ç–¥—ã—Ö–∞—é."
Label: Non-ADE

Tweet: """,

    "de": """
Klassifiziere, ob der Tweet ein Nebenwirkung (ADE) enth√§lt oder nicht. Antworte mit 'ADE' oder 'Non-ADE'.

Tweet: "Nach der Einnahme von Ibuprofen hatte ich starke Kopfschmerzen."
Label: ADE

Tweet: "Ich genie√üe das Wetter und nehme keine Medikamente."
Label: Non-ADE

Tweet: "Ich habe Paracetamol genommen und einen Ausschlag bekommen."
Label: ADE

Tweet: "F√ºhle mich heute ohne Medikamente sehr gut."
Label: Non-ADE

Tweet: "Aspirin hat mir √úbelkeit verursacht."
Label: ADE

Tweet: "Spaziergang im Park heute."
Label: Non-ADE

Tweet: """,

    "fr": """
Classifiez si le tweet contient un effet ind√©sirable (ADE) ou non. R√©pondez uniquement par 'ADE' ou 'Non-ADE'.

Tweet: "J'ai pris de l'ibuprof√®ne et j'ai eu une forte migraine."
Label: ADE

Tweet: "Je suis all√© me promener, pas de m√©dicaments aujourd'hui."
Label: Non-ADE

Tweet: "Apr√®s avoir pris du parac√©tamol, j'ai eu une √©ruption cutan√©e."
Label: ADE

Tweet: "Aucun sympt√¥me aujourd'hui, je vais bien."
Label: Non-ADE

Tweet: "La mirtazapine m'a donn√© des jambes lourdes."
Label: ADE

Tweet: "Je regarde un film tranquille."
Label: Non-ADE

Tweet: """
}

# Load Zephyr model
model_name = "HuggingFaceH4/zephyr-7b-alpha"
tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=True)
model = AutoModelForCausalLM.from_pretrained(model_name, torch_dtype=torch.float16, device_map="auto")
model.eval()

# Predict using model.generate()
y_true, y_pred = [], []
device = model.device

with torch.no_grad():
    for i, row in df.iterrows():
        lang = row['language'] if row['language'] in prompt_dict else 'en'
        prompt = prompt_dict[lang] + row['text'] + "\nLabel:"
        inputs = tokenizer(prompt, return_tensors="pt", truncation=True).to(device)
        output = model.generate(**inputs, max_new_tokens=10)
        decoded = tokenizer.decode(output[0], skip_special_tokens=True)
        predicted = decoded[len(prompt):].strip().lower()

        if 'non' in predicted and 'ade' in predicted:
            y_pred.append(0)
        elif 'ade' in predicted:
            y_pred.append(1)
        else:
            y_pred.append(0)

        y_true.append(row['label'])

# Metrics
acc = accuracy_score(y_true, y_pred)
f1_bin = f1_score(y_true, y_pred)
f1_macro = f1_score(y_true, y_pred, average='macro')

print("\nüìä Evaluation Results with Zephyr-7B (Per-Language Prompting, Full Dataset):")
print(f"Accuracy     : {acc:.4f}")
print(f"F1 Score     : {f1_bin:.4f}")
print(f"F1 Macro     : {f1_macro:.4f}")